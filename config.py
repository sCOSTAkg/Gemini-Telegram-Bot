from google.genai import types
conf = {
    "error_info":           "‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\n–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫!\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∏–ª–∏ —Å–≤—è–∂–∏—Ç–µ—Å—å —Å –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º!",
    "before_generate_info": "ü§ñ–ì–µ–Ω–µ—Ä–∞—Ü–∏—èü§ñ",
    "download_pic_notify":  "ü§ñ–ó–∞–≥—Ä—É–∂–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µü§ñ",
    "model_1":              "gemini-2.5-flash",
    "model_2":              "gemini-2.5-pro",
    "model_3":              "gemini-2.0-flash-preview-image-generation",#for draw
    "streaming_update_interval": 0.5,  # –ò–Ω—Ç–µ—Ä–≤–∞–ª –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ—Ç–æ–∫–∞ –æ—Ç–≤–µ—Ç–∞ (—Å–µ–∫—É–Ω–¥—ã)
}

safety_settings = [
    types.SafetySetting(
        category="HARM_CATEGORY_HARASSMENT",
        threshold="BLOCK_NONE",
    ),
    types.SafetySetting(
        category="HARM_CATEGORY_HATE_SPEECH",
        threshold="BLOCK_NONE",
    ),
    types.SafetySetting(
        category="HARM_CATEGORY_SEXUALLY_EXPLICIT",
        threshold="BLOCK_NONE",
    ),
    types.SafetySetting(
        category="HARM_CATEGORY_DANGEROUS_CONTENT",
        threshold="BLOCK_NONE",
    ),
    types.SafetySetting(
        category="HARM_CATEGORY_CIVIC_INTEGRITY",
        threshold="BLOCK_NONE",
    )
]

generation_config = types.GenerateContentConfig(
    response_modalities=['Text', 'Image'],
    safety_settings=safety_settings,
)
